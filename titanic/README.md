# Titanic - Machine Learning from Disaster

Here is the link to the project:

[Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic)

## First thoughts

I first stumbled upon this dataset when I was taking a school module - "Machine Learning". We were tasked to solve this problem as a team of 5 and submit our predictions to Kaggle. Of course, grades were on the line so we did it blindly following notebooks which are readily available on Kaggle. We used a classifier I forgot (possibly XGBoost) to achieve an accuracy of ~80%. We were happy with the results and moved on to the next project. However, 5 months later (today), I decide to give it a go using techniques/knowledge that I have.

## Reflection

As seen in the notebook, I need to work more on my EDA. Luckily enough, this dataset was not too "dirty". My model achieved an accuracy of `0.767` so I'm not too upset.